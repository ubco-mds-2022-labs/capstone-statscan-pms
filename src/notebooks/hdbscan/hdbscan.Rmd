---
title: "HDBSCAN"
subtitle: "With Log-Transformed Data"
author: "PMS"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, cache=TRUE, fig.width=8, fig.height=6, fig.align = 'center')
```


* * *

```{r, message=FALSE}
# loading libraries
set.seed(2023)
library(cluster)
library(ggplot2)
library(factoextra)
library(clusterCrit)

# load algorithm library
library(dbscan)

# loading data
load('../../../../local_data/codes/create_master/master_pms_df.Rdata')

# covert populations to numeric from factor
master$PMS_DBPOP = as.numeric(gsub("[^0-9.-]", "", as.character(master$PMS_DBPOP)))
master$PMS_CSDPOP = as.numeric(gsub("[^0-9.-]", "", as.character(master$PMS_CSDPOP)))

# subsampling data (if needed)
perc = 5 #percentage of data to subsample
subsample = (nrow(master)/100)*perc
master = master[sample(nrow(master), subsample),]

# variables to cluster with
#clust_vars = c('CSD_AREA', 'PMS_CSDPOP', 'PMS_DBPOP', 'IOR_Index_of_remoteness', 'PMS_CMATYPE')
clust_vars = c()

# amenity names
amenities = c("PMS_prox_idx_emp", "PMS_prox_idx_pharma", "PMS_prox_idx_childcare", "PMS_prox_idx_health", "PMS_prox_idx_grocery", "PMS_prox_idx_educpri", "PMS_prox_idx_educsec", "PMS_prox_idx_lib", "PMS_prox_idx_parks", "PMS_prox_idx_transit")

# cutoff values for all amenities
all_cutoffs = list()

#cutoff function
#https://stats.stackexchange.com/questions/586937/identify-the-point-of-intersection-from-two-distributions
cutoff = function(x, y){
  # Find global minimum and maximum
  xymin <- min(x,y)
  xymax <- max(x,y)
# Estimate densities
  dx <- density(x, n=512, from=xymin, to=xymax)
  dy <- density(y, n=512, from=xymin, to=xymax)

# Plot results
  #plot(dx, xlim=c(xymin, xymax), type="l", lwd=3, xlab="X", ylab="Density", main="")
  #lines(dy, col="red", lwd=3)

# Differences in densities
  dx$diff <- dx$y - dy$y
  ex <- NULL  # Store the intersection points
  ey <- NULL
  k = 0
  for (i in 2:length(dx$x)) {
      # Look for a change in sign of the difference in densities
      if (sign(dx$diff[i-1]) != sign(dx$diff[i])) {
         k = k + 1
         # Linearly interpolate
         ex[k] <- dx$x[i-1] + (dx$x[i]-dx$x[i-1])*(0-dx$diff[i-1])/(dx$diff[i]-dx$diff[i-1])
         ey[k] <- dx$y[i-1] + (dx$y[i]-dx$y[i-1])*(ex[k]-dx$x[i-1])/(dx$x[i]-dx$x[i-1])
         #lines(c(ex[k],ex[k]), c(0,ey[k])) #more plotting
         #points(ex[k], ey[k], pch=16, col="green" )
    }
  }
  exf = ex[ey > 0.1 & ex > 0.01]
  eyf = ey[ey > 0.1 & ex > 0.01]

  if (length(exf) > 1){
    #stop('More than one intersection above 1 detected! Change y-axis threshold.')
    exf = exf[1]
    eyf = eyf[1]
  }

  return(c(exf, eyf))
}

#mode function
Mode = function(x){
  ux = unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#print list items function for profiles
print_list = function(x, cl){
  df = as.data.frame(x)
  if (ncol(df) == 1){
    df = as.data.frame(t(df))
    row.names(df) = ''
  }
  names(df) = paste('Cluster', cl)
  print(df)
  cat('\n\n')
}
```


# Introduction 

The following analysis is an implementation of the \href{https://pberba.github.io/stats/2020/07/08/intro-hdbscan/}{HDBSCAN} algorithm on individual, log-scaled proximity measures (no auxiliary variables included).

Please note that for the following plots, HDBSCAN considers cluster 1 to be "noise points" and are thus not part of an actual cluster. 


# Assumptions of the Alogrithm

\href{https://rdrr.io/cran/dbscan/man/hdbscan.html}{This} fast implementation of HDBSCAN (Campello et al., 2013) computes the hierarchical cluster tree representing density estimates along with the stability-based flat cluster extraction. HDBSCAN essentially computes the hierarchy of all DBSCAN* clusterings, and then uses a stability-based extraction method to find optimal cuts in the hierarchy, thus producing a flat solution.

HDBSCAN performs the following steps:

* Compute mutual reachability distance mrd between points (based on distances and core distances).
* Use mdr as a distance measure to construct a minimum spanning tree.
* Prune the tree using stability.
* Extract the clusters.




```{r, warning=FALSE}
#algorithm function --> must return: data with no NAs, cluster assignments
algo = function(dataset, amen_name, num=NULL){
  
  #log transform PM
  dataset = log(dataset+0.0001)
  
  res = hdbscan(as.matrix(dataset), minPts = 200)
  
  sil_coef = intCriteria(as.matrix(dataset),as.integer(res$cluster), 'Silhouette')$silhouette
  xeni_beni = intCriteria(as.matrix(dataset),as.integer(res$cluster), 'Xie_Beni')$xie_beni
  davies = intCriteria(as.matrix(dataset),as.integer(res$cluster), 'Davies_Bouldin')$davies_bouldin
  dunn = intCriteria(as.matrix(dataset),as.integer(res$cluster), 'Dunn')$dunn
  calinski = intCriteria(as.matrix(dataset),as.integer(res$cluster), 'Calinski_Harabasz')$calinski_harabasz
  
  #if only 1 cluster
  if (length(unique(res$cluster)) == 1){
    print('NO CLUSTERS DETECTED')
    return(NA)
  }
  
  plot(res, show_flat = T)
  
  #print
  print(paste('Silhouette coefficient:', sil_coef))
  print(paste('Xie Beni coefficient:', xeni_beni))
  print(paste('Davies Bouldin coefficient:', davies))
  print(paste('Dunn Index coefficient:', dunn))
  print(paste('Calinski-Harabasz coefficient:', calinski))
  
  #unlog the PM
  dataset = exp(dataset)-0.0001
  
  return(list('complete_data' = dataset, 'clusts' = as.integer(res$cluster)))
}

#master function
do_everything = function(dataset, amen_name, num){
  # remove NA values
  amen = dataset[!is.na(dataset[,amen_name]),]
  clust_data = dataset[!is.na(dataset[,amen_name]),c(amen_name, clust_vars)]
  
  # algorithm
  res = algo(clust_data, amen_name, num)
  if (is.na(res)){
    return(NA)
  }
  
  # store cluster results
  clusts = res$clusts+1
  comp_data = res$complete_data[!(clusts == 1)]
  clusts = clusts[!(clusts == 1)]
  clusts = clusts-1
  rm(res)
  
  #reorder clusters
  # ...
  
  #find cutoffs
  cutoffs = c()
  for (i in 1:(length(unique(clusts))-1)){
    temp = comp_data[clusts==unique(clusts)[i]]
    temp2 = comp_data[clusts==unique(clusts)[i+1]]
    values = c(max(temp), min(temp2))
    cutoffs[i] = mean(values)
  }
  all_cutoffs = list()
  all_cutoffs[[amen_name]] = cutoffs
  
  barplot(as.matrix(table(clusts)/length(clusts)), col=sort(unique(clusts)), ylim=c(0, 4), horiz=TRUE, xlab='Proportion', main='Proportion of DBs in each cluster')
  legend(0, 2.2, lty=1, lwd=2, col=sort(unique(clusts)), legend = c(paste('Cluster', sort(unique(clusts)))))
  
  # re-assign clusters so that they're in order
  # comp = list()
  # for (i in unique(clusts)){
  #   temp = amen[clusts == i,amen_name]
  #   comp[[i]] = Mode(round(temp, 6))
  # }
  # if (max(unlist(comp)) == comp[[1]]){
  #   ord = match(comp, comp[order(unlist(comp))])
  # } else{
  #   ord = match(comp[order(unlist(comp))], comp) 
  # }
  # if (sum(duplicated(ord))>0){
  #   ord[duplicated(ord)] = unique(clusts)[which(!(unique(clusts) %in% ord))]
  # }
  # clusts = ord[clusts]
  
  # plot
  # pass = list(data = comp_data, cluster = clusts)
  # plot(fviz_cluster(pass, ellipse.type = "norm") + theme_minimal())
  
  # cutoffs = list()
  # plot(density(amen[clusts == 1,amen_name]), xlim=c(0, 1), lwd=2, xlab="X", ylab="Density", main="")
  # for (j in 1:(length(unique(clusts))-1)){
  #     cutoffs[[j]] = cutoff(amen[clusts == j,amen_name], amen[clusts == j+1,amen_name])
  #     all_cutoffs[[amen_name]][j] = cutoffs[[j]][1]
  # 
  #     lines(density(amen[clusts == j+1,amen_name]), col=(j+1), lwd=2)
  #     points(cutoffs[[j]][1], cutoffs[[j]][2], pch=16, col="green" )
  # }
  print('Segment cutoff values:')
  for (a in 1:length(cutoffs)){
    print(cutoffs[a])
  }
  
  #silhouette plot
  sil = silhouette(clusts, dist(comp_data))
  plot(fviz_silhouette(sil))
  
  #profiles
  print('Cluster profiles:')
  profiles = list()
  for (k in sort(unique(clusts))){
    temp = dataset[clusts == k,]
    profiles[[amen_name]][k] = round(mean(temp[,amen_name], na.rm = T), 5)
    profiles[['Count']][k] = as.character(nrow(temp))
    profiles[['DB_population']][k] = round(mean(temp$PMS_DBPOP, na.rm = T), 1)
    profiles[['CSD_population']][k] = round(mean(temp$PMS_CSDPOP, na.rm = T), 1)
    profiles[['CMA_type']][[k]] = summary(temp$PMS_CMATYPE)
    profiles[['Index_of_Remoteness']][k] = round(mean(temp$IOR_Index_of_remoteness, na.rm = T), 3)
    profiles[['Provinces']][[k]] = summary(temp$PROVINCE)
    profiles[['Amenity_dense']][[k]] = summary(temp$PMS_amenity_dense)
  }
  #printing profiles
  print('Num of DBs:')
  print_list(profiles[['Count']], sort(unique(clusts)))
  cat('\n DB Population: \n')
  print_list(profiles[['DB_population']], sort(unique(clusts)))
  cat('\n CSD Population: \n')
  print_list(profiles[['CSD_population']], sort(unique(clusts)))
  cat('\n CMA Type: \n')
  print_list(profiles[['CMA_type']], sort(unique(clusts)))
  cat('\n Index of Remoteness: \n')
  print_list(profiles[['Index_of_Remoteness']], sort(unique(clusts)))
  cat('\n Provinces: \n')
  print_list(profiles[['Provinces']], sort(unique(clusts)))
  cat('\n Amenity dense: \n')
  print_list(profiles[['Amenity_dense']], sort(unique(clusts)))
  cat('\n', amen_name, ': \n')
  print_list(profiles[[amen_name]], sort(unique(clusts)))
  
  #return all_cutoff values
  # tab = list()
  # for (a in unique(clusts)){
  #   tab[[amen_name]][a] = as.matrix(table(clusts)/length(clusts))[a]
  # }
  return(all_cutoffs)
}
```



*** 


\pagebreak
# Amenities

## Employment

```{r}
lst = do_everything(master, 'PMS_prox_idx_emp', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Pharmacy

```{r}
lst = do_everything(master, 'PMS_prox_idx_pharma', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Childcare

```{r}
lst = do_everything(master, 'PMS_prox_idx_childcare', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Health

```{r}
lst = do_everything(master, 'PMS_prox_idx_health', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Grocery

```{r}
lst = do_everything(master, 'PMS_prox_idx_grocery', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Primary Education

```{r}
lst = do_everything(master, 'PMS_prox_idx_educpri', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Secondary Education

```{r}
lst = do_everything(master, 'PMS_prox_idx_educsec', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Libraries

```{r}
lst = do_everything(master, 'PMS_prox_idx_lib', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Parks

```{r}
lst = do_everything(master, 'PMS_prox_idx_parks', NULL)
all_cutoffs = append(all_cutoffs, lst)
```


*** 

\pagebreak
## Transit

```{r}
lst = do_everything(master, 'PMS_prox_idx_transit', NULL)
all_cutoffs = append(all_cutoffs, lst)
```





*** 


\pagebreak
# Conclusion

text


```{r, warning=FALSE, message=FALSE}
dput(all_cutoffs)
# concluding graphic
# library(ggplot2)
# library(tidyverse)
# plt = as.data.frame(sapply(all_cutoffs, '[', seq(max(sapply(all_cutoffs, length)))))
# names(plt) = amenities
# plt = pivot_longer(plt, cols=amenities)
# #plt$group = as.factor(match(plt$name, amenities))
# plt$num = as.factor(rep(1:4, each=10))
# 
# ggplot(plt, aes(x = value, y = name)) + 
#   geom_col(aes(fill=num)) + theme_minimal() + 
#   ggtitle('Proximity Measure Cut-off Values') + 
#   ylab('Amenity') + xlab('Value') + labs(fill = 'Cluster #')
```






